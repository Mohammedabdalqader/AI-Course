{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = make_blobs(n_samples=1000, n_features=4,centers=2,random_state=5)\n",
    "\n",
    "features = data[0]\n",
    "labels   = data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spliting the Dataset\n",
    "\n",
    "Here we use function from sklearn Library to split our data into train dataset to train our model on it and test dataset to test our model after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train,features_test,labels_train,labels_test = train_test_split(features,labels,test_size=0.30, random_state=1991)\n",
    "labels_train = labels_train.reshape(1,len(labels_train))\n",
    "labels_test = labels_test.reshape(1,len(labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the shape of train as well as test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Your training dataset consist of {} samples and {} features and the shape = \".format(features_train.shape[0],features_train.shape[1]), features_train.shape)\n",
    "print(\"\\nYour test dataset consist of {} samples and {} features and the shape = \".format(features_test.shape[0],features_test.shape[1]), features_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to build a neural network with 2 hidden layers, each containing (8) neurons and output Layer with single neuron\n",
    "Activation Function : Sigmoid\n",
    "\n",
    "Loss Function : Least Square Error "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.A\n",
    "\n",
    "##### Initialize the weight and bias for each Hidden Layer as well as output Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1991)\n",
    "# I will initialize the first Hidden Layer Weight & bias for You\n",
    "\n",
    "weight_h1 = np.random.rand(8,4)  ## 4 : number of features (number of inputs in the first Hidden Layer)   &&  8 : number of neurons in the first Hidden layer\n",
    "bias_h1   = np.random.rand(8,1)  ## 8 : number of neurons in the first Hidden Layer \n",
    "\n",
    "\n",
    "##### Write Your Code Here ####\n",
    "weight_h2 = \n",
    "bias_h2   = \n",
    "\n",
    "\n",
    "weight_o3 = \n",
    "bias_o3   = \n",
    "\n",
    "# then save all weights in one variable and all bias in one variable\n",
    "weight = (weight_h1,weight_h2,weight_o3)\n",
    "bias   = (bias_h1,bias_h2,bias_o3)\n",
    "\n",
    "# you can get weight_h1 for example like this   \n",
    "# weight_h1 = weight[0]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.B\n",
    "\n",
    "Write a Class that contains 4 Functions ( sigmoid , loss function , forward_propagation, backward_propagation)\n",
    "\n",
    "\n",
    "Least square Error = \n",
    "<img src=\"https://latex.codecogs.com/gif.latex?(1/n)&space;*&space;\\sum&space;(labels&space;-&space;pred)^{2}\" title=\"(1/n) * \\sum (labels - pred)^{2}\" />\n",
    "\n",
    "n = number of samples ... in your case it's 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deep_Neural_Network():\n",
    "    \n",
    "    def __init__(self,features_train,labels_train,weight,bias,learning_rate):\n",
    "        \n",
    "        self.features_train = features_train\n",
    "        self.labels_train   = labels_train\n",
    "        self.weight         = weight\n",
    "        self.bias           = bias\n",
    "        self.learning_rate  = learning_rate\n",
    "        \n",
    "    def sigmoid(self,z):\n",
    "        ### Write the function of Sigmoid then return the result\n",
    "        ### Write your code here ### \n",
    "    \n",
    "\n",
    "    def least_square_error(self,labels_train,y_pred):\n",
    "        #### compute the loss \n",
    "        return loss\n",
    "        \n",
    "        \n",
    "    def forward_propagation(self):\n",
    "        ### Here you will implement the feedforward of the Neural_Network\n",
    "        first_hidden_layer_out  = np.add(np.dot(self.weight[0],self.features_train.T) , self.bias[0])\n",
    "        first_activation        = self.sigmoid(first_hidden_layer_out)\n",
    "        ### Write your code here  ###\n",
    "        \n",
    "        second_hidden_layer_out = \n",
    "        second_activation       = \n",
    "        \n",
    "        output_layer            = \n",
    "        output_activation       = \n",
    "        \n",
    "        y_pred = output_activation        \n",
    "        ### compute the loss\n",
    "        \n",
    "        loss = self.least_square_error(self.labels_train,y_pred)\n",
    "        \n",
    "        cache = ((first_hidden_layer_out,second_hidden_layer_out,output_layer),(first_activation,second_activation,y_pred))\n",
    "        return y_pred,loss,cache\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def backward_propagation(self,y_pred,cache):\n",
    "        \n",
    "        dy_pred = -2*(self.labels_train - y_pred)\n",
    "        ### Write your code here  ###\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ##### update your weight and bias (weight_h1,weight_h2,weight_o3......bias_h1,bias_h2,bias_o3)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Deep_Neural_Network(features_train,labels_train,weight,bias,learning_rate=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to train your model :D\n",
    "epochs = 15000\n",
    "for epochs in range(epochs):\n",
    "        y_pred, loss, cache = model.forward_propagation()\n",
    "        model.backward_propagation(y_pred,cache)\n",
    "        if (epochs % 3000 == 0):\n",
    "            print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here You can test your model and see tha accuracy :D\n",
    "\n",
    "you just need to run both cells to see how good is your model and Good Luck "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(features_test,labels_test):\n",
    "    \n",
    "    h1  = np.add(np.dot(model.weight[0],features_test.T) , model.bias[0])\n",
    "    a1  = model.sigmoid(h1)\n",
    "        \n",
    "    h2  = np.add(np.dot(model.weight[1],a1) , model.bias[1])\n",
    "    a2  = model.sigmoid(h2)\n",
    "        \n",
    "    out = np.add(np.dot(model.weight[2],a2) , model.bias[2])\n",
    "    a3  = model.sigmoid(out)\n",
    "        \n",
    "    y_pred = a3\n",
    "                \n",
    "    loss = model.least_square_error(labels_test,y_pred)\n",
    "    \n",
    "    correct_answer = 0\n",
    "    \n",
    "    for i in range(features_test.shape[0]):\n",
    "        if (labels_test[0][i] == np.round(y_pred[0][i])):\n",
    "            correct_answer +=1\n",
    "            \n",
    "    \n",
    "    accuracy = (correct_answer / features_test.shape[0]) * 100\n",
    "    \n",
    "    return accuracy\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = test(features_test,labels_test)\n",
    "print(\"The accuracy of your model is {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
